# spike_tab.py
import polars as pl
import streamlit as st
import plotly.graph_objects as go
from datetime import datetime
from dateutil.relativedelta import relativedelta
from typing import Optional, List

from dashboard.utils.analysis import perform_spike_detection, get_spike_time_series
from dashboard.utils.constants import ColumnNames


def show(filters=None, lf: pl.LazyFrame = None):
    """
    Spike Detection íƒ­

    Args:
        filters: SidebarManagerì—ì„œ ìƒì„±ëœ í•„í„° ë”•ì…”ë„ˆë¦¬
            - date_range: (start_date, end_date) íŠœí”Œ
            - as_of_month: ê¸°ì¤€ ì›” (ì˜ˆ: "2025-11")
            - window: ìœˆë„ìš° í¬ê¸° (1 ë˜ëŠ” 3)
            - min_c_recent: ìµœì†Œ ìµœê·¼ ì¼€ì´ìŠ¤ ìˆ˜
            - z_threshold: Z-score ì„ê³„ê°’
            - eps: Epsilon ê°’
            - alpha: ìœ ì˜ìˆ˜ì¤€
            - correction: ë‹¤ì¤‘ê²€ì • ë³´ì • ë°©ë²•
            - min_methods: ì•™ìƒë¸” ìµœì†Œ ë°©ë²• ìˆ˜
        lf: MAUDE ë°ì´í„° LazyFrame
    """
    st.title("ğŸ“ˆ Spike Detection")

    if lf is None:
        st.warning("ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return

    # í•„í„°ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©
    if filters is None:
        filters = {}

    # í•„í„° ê°’ ì¶”ì¶œ
    as_of_month = filters.get('as_of_month', '2025-11')
    window = filters.get('window', 1)
    min_c_recent = filters.get('min_c_recent', 20)
    z_threshold = filters.get('z_threshold', 2.0)
    eps = filters.get('eps', 0.1)
    alpha = filters.get('alpha', 0.05)
    correction = filters.get('correction', 'fdr_bh')
    min_methods = filters.get('min_methods', 2)

    # ìŠ¤íŒŒì´í¬ íƒì§€ ìˆ˜í–‰ (ê¸°ë³¸ê°’ìœ¼ë¡œ ë¯¸ë¦¬ ê³„ì‚°)
    with st.spinner("ìŠ¤íŒŒì´í¬ íƒì§€ ë¶„ì„ ì¤‘..."):
        result_df = outlier_detect_check(
            lf=lf,
            window=window,
            min_c_recent=min_c_recent,
            z_threshold=z_threshold,
            eps=eps,
            alpha=alpha,
            correction=correction,
            min_methods=min_methods,
            month=as_of_month,
        )

    if result_df is None or len(result_df) == 0:
        st.info("ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # ê²°ê³¼ í‘œì‹œ
    st.success(f"ì´ {len(result_df)}ê°œì˜ í‚¤ì›Œë“œë¥¼ ë¶„ì„í–ˆìŠµë‹ˆë‹¤.")

    # íŒ¨í„´ë³„ ìš”ì•½
    pattern_counts = result_df.group_by("pattern").agg(pl.len().alias("count")).sort("count", descending=True)
    st.subheader("ğŸ“Š íŒ¨í„´ë³„ ë¶„í¬")

    col1, col2, col3, col4 = st.columns(4)
    pattern_map = {
        "severe": ("ğŸ”´ Severe", col1),
        "alert": ("ğŸŸ  Alert", col2),
        "attention": ("ğŸŸ¡ Attention", col3),
        "general": ("ğŸŸ¢ General", col4)
    }

    for pattern, (label, col) in pattern_map.items():
        count = pattern_counts.filter(pl.col("pattern") == pattern)
        count_val = count["count"][0] if len(count) > 0 else 0
        col.metric(label, count_val)

    # ìŠ¤íŒŒì´í¬ í‚¤ì›Œë“œë§Œ í•„í„°ë§ (ì•™ìƒë¸” ê¸°ì¤€)
    spike_df = result_df.filter(pl.col("is_spike_ensemble") == True)

    # ì‹œê³„ì—´ ë°ì´í„° ì¤€ë¹„ (12ê°œì›”)
    end_date = datetime.strptime(as_of_month, "%Y-%m")
    start_date = end_date - relativedelta(months=11)
    start_month = start_date.strftime("%Y-%m")

    # 1. ì´ìƒ íƒì§€ ê·¸ë˜í”„ (ë¹„ìœ¨ ì‹œê³„ì—´)
    st.subheader("ğŸ“ˆ í‚¤ì›Œë“œ ë¹„ìœ¨ ì¶”ì´ (Anomaly Detection)")

    # TopN í•„í„° ë° ì •ë ¬ ê¸°ì¤€ ì„ íƒ
    col_filter1, col_filter2, col_filter3 = st.columns([1, 1, 2])
    with col_filter1:
        top_n_chart = st.number_input(
            "í‘œì‹œí•  í‚¤ì›Œë“œ ìˆ˜",
            min_value=1,
            max_value=20,
            value=13,
            step=1,
            key="top_n_chart"
        )

    with col_filter2:
        sort_by = st.selectbox(
            "ì •ë ¬ ê¸°ì¤€",
            options=["ratio", "n_methods", "score_pois", "C_recent"],
            format_func=lambda x: {
                "ratio": "ë¹„ìœ¨ (Ratio)",
                "n_methods": "ìŠ¤íŒŒì´í¬ ë°©ë²• ìˆ˜",
                "score_pois": "Poisson ì ìˆ˜",
                "C_recent": "ìµœê·¼ ë³´ê³ ìˆ˜"
            }[x],
            index=0,
            key="sort_by_chart"
        )

    # TopNì— ë§ì¶° í‚¤ì›Œë“œ ì„ íƒ (ì •ë ¬ ê¸°ì¤€ ì ìš©)
    top_keywords_filtered = get_top_n_keywords(
        result_df=result_df,
        spike_df=spike_df,
        top_n=top_n_chart,
        sort_by=sort_by
    )

    # í•„í„°ë§ëœ í‚¤ì›Œë“œë¡œ ì‹œê³„ì—´ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    if len(top_keywords_filtered) > 0:
        ts_df_filtered = get_spike_time_series(
            _lf=lf,
            keywords=top_keywords_filtered,
            start_month=start_month,
            end_month=as_of_month
        )

        if len(ts_df_filtered) > 0:
            fig = create_spike_chart(ts_df_filtered, z_threshold, as_of_month, window)
            st.plotly_chart(fig, width='stretch')
        else:
            st.info("ì‹œê³„ì—´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.info("ì‹œê³„ì—´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    # 2. ì „ì²´ ê²°ê³¼ í…Œì´ë¸” (íŒ¨í„´ë³„ í•„í„°ë§ ê°€ëŠ¥)
    st.subheader("ğŸ“‹ ì „ì²´ ë¶„ì„ ê²°ê³¼")

    # íŒ¨í„´ í•„í„°
    col_pattern, col_topn = st.columns([2, 2])
    with col_pattern:
        pattern_filter = st.multiselect(
            "íŒ¨í„´ í•„í„°",
            options=["severe", "alert", "attention", "general"],
            default=["severe", "alert", "attention"],
            format_func=lambda x: {
                "severe": "ğŸ”´ Severe",
                "alert": "ğŸŸ  Alert",
                "attention": "ğŸŸ¡ Attention",
                "general": "ğŸŸ¢ General"
            }[x]
        )

    with col_topn:
        top_n_table = st.number_input(
            "í‘œì‹œí•  í–‰ ìˆ˜",
            min_value=10,
            max_value=100,
            value=50,
            step=10,
            key="top_n_table"
        )

    # í•„í„°ë§ëœ ê²°ê³¼ í…Œì´ë¸”
    filtered_result = result_df.filter(pl.col("pattern").is_in(pattern_filter))
    display_all_df = prepare_spike_table(filtered_result.head(top_n_table))
    st.dataframe(display_all_df, width='stretch', height=600)

    # 3. ìŠ¤íŒŒì´í¬ í‚¤ì›Œë“œ ìš”ì•½
    if len(spike_df) > 0:
        st.subheader(f"âš ï¸ ìŠ¤íŒŒì´í¬ íƒì§€ í‚¤ì›Œë“œ ìš”ì•½ ({len(spike_df)}ê°œ)")
        spike_summary_df = prepare_spike_table(spike_df.head(20))
        st.dataframe(spike_summary_df, width='stretch', height=400)
    else:
        st.info("íƒì§€ëœ ìŠ¤íŒŒì´í¬ê°€ ì—†ìŠµë‹ˆë‹¤.")

    # 4. ì „ì²´ ë°ì´í„° ë‹¤ìš´ë¡œë“œ
    st.subheader("ğŸ“¥ ì „ì²´ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ")
    csv = result_df.write_csv()
    st.download_button(
        label="CSV ë‹¤ìš´ë¡œë“œ",
        data=csv,
        file_name=f"spike_detection_{as_of_month}_w{window}.csv",
        mime="text/csv"
    )


def get_top_n_keywords(
    result_df: pl.DataFrame,
    spike_df: pl.DataFrame,
    top_n: int,
    sort_by: str = "ratio"
) -> List[str]:
    """TopN í‚¤ì›Œë“œë¥¼ ì •ë ¬ ê¸°ì¤€ì— ë”°ë¼ ì„ íƒ

    Args:
        result_df: ì „ì²´ ê²°ê³¼ DataFrame
        spike_df: ìŠ¤íŒŒì´í¬ë§Œ í•„í„°ë§ëœ DataFrame
        top_n: ì„ íƒí•  í‚¤ì›Œë“œ ìˆ˜
        sort_by: ì •ë ¬ ê¸°ì¤€ ("ratio", "n_methods", "score_pois", "C_recent")

    Returns:
        ì„ íƒëœ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
    """
    # í•­ìƒ ì „ì²´ ê²°ê³¼ì—ì„œ ì„ íƒ (ìŠ¤íŒŒì´í¬ê°€ ì ì„ ìˆ˜ ìˆìŒ)
    if len(result_df) == 0:
        return []

    # ì •ë ¬ ê¸°ì¤€ì— ë”°ë¼ ì •ë ¬
    sorted_df = result_df.sort(sort_by, descending=True)

    # ìƒìœ„ Nê°œ í‚¤ì›Œë“œ ì¶”ì¶œ
    top_keywords = sorted_df.head(top_n)["keyword"].to_list()

    return top_keywords


def outlier_detect_check(
    lf: pl.LazyFrame,
    window: int = 1,
    min_c_recent: int = 20,
    z_threshold: float = 2.0,
    eps: float = 0.1,
    alpha: float = 0.05,
    correction: str = 'fdr_bh',
    min_methods: int = 2,
    month: str = "2025-11",
) -> Optional[pl.DataFrame]:
    """
    ìŠ¤íŒŒì´í¬ íƒì§€ ë¶„ì„ ìˆ˜í–‰

    Args:
        lf: MAUDE ë°ì´í„° LazyFrame
        window: ìœˆë„ìš° í¬ê¸° (1 ë˜ëŠ” 3)
        min_c_recent: ìµœì†Œ ìµœê·¼ ì¼€ì´ìŠ¤ ìˆ˜
        z_threshold: Z-score ì„ê³„ê°’
        eps: Epsilon ê°’ (z_log ê³„ì‚°ìš©)
        alpha: ìœ ì˜ìˆ˜ì¤€ (Poisson ê²€ì •ìš©)
        correction: ë‹¤ì¤‘ê²€ì • ë³´ì • ë°©ë²• ('bonferroni', 'sidak', 'fdr_bh', None)
        min_methods: ì•™ìƒë¸” ìŠ¤íŒŒì´í¬ íŒì • ìµœì†Œ ë°©ë²• ìˆ˜
        month: ê¸°ì¤€ ì›” (ì˜ˆ: "2025-11")

    Returns:
        ìŠ¤íŒŒì´í¬ íƒì§€ ê²°ê³¼ DataFrame
        ì»¬ëŸ¼: keyword, C_recent, C_base, ratio, z_log, score_pois,
              is_spike, is_spike_z, is_spike_p, n_methods, is_spike_ensemble, pattern
    """
    result_df = perform_spike_detection(
        _lf=lf,
        as_of_month=month,
        window=window,
        min_c_recent=min_c_recent,
        z_threshold=z_threshold,
        eps=eps,
        alpha=alpha,
        correction=correction,
        min_methods=min_methods,
    )

    return result_df


def create_spike_chart(
    ts_df: pl.DataFrame,
    z_threshold: float,
    as_of_month: str,
    window: int
) -> go.Figure:
    """
    ìŠ¤íŒŒì´í¬ ì‹œê³„ì—´ ì°¨íŠ¸ ìƒì„±

    Args:
        ts_df: ì‹œê³„ì—´ ë°ì´í„° (columns: month, keyword, count, ratio)
        z_threshold: Z-score ì„ê³„ê°’ (í‘œì‹œìš©)
        as_of_month: ê¸°ì¤€ ì›”
        window: ìœˆë„ìš° í¬ê¸°

    Returns:
        Plotly Figure ê°ì²´
    """
    fig = go.Figure()

    # í‚¤ì›Œë“œë³„ë¡œ ë¼ì¸ ì¶”ê°€
    keywords = ts_df["keyword"].unique().to_list()

    # ìƒ‰ìƒ íŒ”ë ˆíŠ¸
    colors = [
        '#e6194b', '#3cb44b', '#ffe119', '#4363d8', '#f58231',
        '#911eb4', '#46f0f0', '#f032e6', '#bcf60c', '#fabebe',
        '#008080', '#e6beff', '#9a6324'
    ]

    for i, keyword in enumerate(keywords):
        keyword_data = ts_df.filter(pl.col("keyword") == keyword).sort("month")

        fig.add_trace(go.Scatter(
            x=keyword_data["month"].to_list(),
            y=keyword_data["ratio"].to_list(),
            mode='lines+markers',
            name=keyword,
            line=dict(color=colors[i % len(colors)], width=2),
            marker=dict(size=6),
            hovertemplate='<b>%{fullData.name}</b><br>' +
                         'Month: %{x}<br>' +
                         'Ratio: %{y:.4f}%<br>' +
                         '<extra></extra>'
        ))

    # ë ˆì´ì•„ì›ƒ ì„¤ì •
    fig.update_layout(
        title=f"Spike Detection - Keyword Proportion Over Time (Window: {window}M, Threshold: {z_threshold}Ïƒ)",
        xaxis_title="Month",
        yaxis_title="ë¹„ìœ¨ (%) - ì›”ë³„ ì „ì²´ ë³´ê³  ëŒ€ë¹„",
        hovermode='x unified',
        height=600,
        legend=dict(
            orientation="v",
            yanchor="top",
            y=1,
            xanchor="left",
            x=1.02
        ),
        margin=dict(l=50, r=150, t=80, b=50)
    )

    # ê¸°ì¤€ ì›” ê°•ì¡° (shapesë¥¼ ì‚¬ìš©í•˜ì—¬ ì§ì ‘ ê·¸ë¦¬ê¸°)
    if len(ts_df) > 0:
        # xì¶•ì—ì„œ as_of_monthì˜ ì¸ë±ìŠ¤ ì°¾ê¸°
        all_months = sorted(ts_df["month"].unique().to_list())
        if as_of_month in all_months:
            fig.add_shape(
                type="line",
                x0=as_of_month,
                x1=as_of_month,
                y0=0,
                y1=1,
                yref="paper",
                line=dict(color="red", width=2, dash="dash")
            )
            # ì£¼ì„ ì¶”ê°€
            fig.add_annotation(
                x=as_of_month,
                y=1,
                yref="paper",
                text="Analysis Month",
                showarrow=False,
                yshift=10,
                font=dict(color="red", size=10)
            )

    return fig


def prepare_spike_table(spike_df: pl.DataFrame) -> pl.DataFrame:
    """
    ìŠ¤íŒŒì´í¬ í…Œì´ë¸” í‘œì‹œìš© ë°ì´í„° ì¤€ë¹„

    Args:
        spike_df: ìŠ¤íŒŒì´í¬ íƒì§€ ê²°ê³¼ DataFrame

    Returns:
        í‘œì‹œìš© DataFrame
    """
    display_df = spike_df.select([
        pl.col("keyword").alias("í‚¤ì›Œë“œ"),
        pl.col("C_recent").alias("ìµœê·¼ ë³´ê³ ìˆ˜"),
        pl.col("C_base").alias("ê¸°ì¤€ ë³´ê³ ìˆ˜"),
        pl.col("ratio").alias("ë¹„ìœ¨"),
        pl.col("is_spike").alias("Spike (Ratio)"),
        pl.col("is_spike_z").alias("Spike (Z-score)"),
        pl.col("is_spike_p").alias("Spike (Poisson)"),
        pl.col("n_methods").alias("ìŠ¤íŒŒì´í¬ ë°©ë²• ìˆ˜"),
        pl.col("pattern").alias("íŒ¨í„´"),
    ])

    # íŒ¨í„´ì— ì´ëª¨ì§€ ì¶”ê°€
    display_df = display_df.with_columns(
        pl.when(pl.col("íŒ¨í„´") == "severe").then(pl.lit("ğŸ”´ Severe"))
        .when(pl.col("íŒ¨í„´") == "alert").then(pl.lit("ğŸŸ  Alert"))
        .when(pl.col("íŒ¨í„´") == "attention").then(pl.lit("ğŸŸ¡ Attention"))
        .otherwise(pl.lit("ğŸŸ¢ General"))
        .alias("íŒ¨í„´")
    )

    return display_df