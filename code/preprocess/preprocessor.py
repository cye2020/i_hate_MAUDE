"""
UDI ì²˜ë¦¬ ë©”ì¸ í´ë˜ìŠ¤ (LazyFrame ê¸°ë°˜, í´ë¦°ì§• ì œê±°)
"""
import polars as pl
from pathlib import Path
# from pprint import pprint
from code.preprocess.config import Config
from code.preprocess.preprocess import (
    extract_di_from_public, 
    fuzzy_match_dict, 
    collect_unique_safe
)
from code.utils.chunk import process_lazyframe_in_chunks


class UDIProcessor:
    """UDI-DI ê²°ì¸¡ ì²˜ë¦¬ í´ë˜ìŠ¤ (LazyFrame ìµœì í™”, í´ë¦°ì§•ëœ ë°ì´í„° ì…ë ¥)"""
    
    def __init__(self, config: Config = None):
        self.config = config or Config()
        self.udi_di_lookup = None
        self.mfr_lookup_full = None
        self.mfr_lookup_partial = None
        self.mfr_mapping = None
    
    # ==================== 1ë‹¨ê³„: ì „ì²˜ë¦¬ (LazyFrame ìœ ì§€) ====================
    
    def preprocess_maude(self, lf: pl.LazyFrame) -> pl.LazyFrame:
        """
        MAUDE ì „ì²˜ë¦¬ (LazyFrame ìœ ì§€)
        - ì´ë¯¸ í´ë¦°ì§•ëœ ë°ì´í„°ë¥¼ ë°›ìŒ
        - manufacturer_std, brandëŠ” ì´ë¯¸ ì •ê·œí™”ë¨
        
        Returns:
            LazyFrame (collect ì•ˆ í•¨)
        """
        print("ğŸ”§ MAUDE ì „ì²˜ë¦¬...")
        
        total_cols = lf.collect_schema().names()
        
        # 1. UDI-Public â†’ DI ì¶”ì¶œ
        result_lf = lf.with_columns([
            pl.col('udi_public')
              .map_elements(extract_di_from_public, return_dtype=pl.Utf8)
              .alias('extracted_di'),
            
            # 2. ë‚ ì§œ í†µí•©
            pl.coalesce([pl.col(c) for c in self.config.MAUDE_DATES if c in total_cols])
              .alias('report_date'),
        ])
        
        # 3. UDI í†µí•©
        result_lf = result_lf.with_columns([
            pl.coalesce(['udi_di', 'extracted_di']).alias('udi_combined'),
            
            pl.when(pl.col('udi_di').is_not_null())
              .then(pl.lit('original'))
              .when(pl.col('extracted_di').is_not_null())
              .then(pl.lit('extracted'))
              .otherwise(pl.lit('missing'))
              .alias('udi_source')
        ])
        
        print(f"   âœ“ ì „ì²˜ë¦¬ ì™„ë£Œ (LazyFrame ìœ ì§€)")
        return result_lf
    
    def preprocess_udi_db(self, lf: pl.LazyFrame) -> pl.LazyFrame:
        """
        UDI DB ì „ì²˜ë¦¬ (LazyFrame ìœ ì§€)
        - ì´ë¯¸ í´ë¦°ì§•ëœ ë°ì´í„°ë¥¼ ë°›ìŒ
        """
        print("ğŸ”§ UDI DB ì „ì²˜ë¦¬...")
        
        total_cols = lf.collect_schema().names()
        # ë‚ ì§œ í†µí•©ë§Œ
        return lf.with_columns([
            pl.coalesce([pl.col(c) for c in self.config.UDI_DATES if c in total_cols])
              .alias('publish_date')
        ])
    
    def normalize_manufacturers(self, maude_lf: pl.LazyFrame, udi_lf: pl.LazyFrame):
        """
        ì œì¡°ì‚¬ëª… í¼ì§€ ë§¤ì¹­ (Uniqueë§Œ collect - ì•ˆì „)
        - manufacturer_stdëŠ” ì´ë¯¸ í´ë¦°ì§•ë¨
        """
        print("ğŸ”§ ì œì¡°ì‚¬ëª… í¼ì§€ ë§¤ì¹­...")
        
        # Uniqueë§Œ collect (ìˆ˜ì²œ ê°œ ìˆ˜ì¤€ - ì•ˆì „)
        maude_mfrs = collect_unique_safe(maude_lf, 'manufacturer')
        udi_mfrs = collect_unique_safe(udi_lf, 'manufacturer')
        
        self.mfr_mapping = fuzzy_match_dict(
            maude_mfrs, 
            udi_mfrs, 
            self.config.FUZZY_THRESHOLD
        )
        
        # pprint([(k, v) for k,v in self.mfr_mapping.items() if k!=v])
        
        print(f"   ë§¤ì¹­: {sum(k!=v for k,v in self.mfr_mapping.items())}/{len(maude_mfrs)} ê±´")
    
    def apply_normalization(self, lf: pl.LazyFrame) -> pl.LazyFrame:
        """ì œì¡°ì‚¬ëª… ì •ê·œí™” ì ìš© (LazyFrame ìœ ì§€)"""
        return lf.with_columns([
            pl.col('manufacturer').replace(self.mfr_mapping).alias('mfr_std')
        ])
    
    # ==================== 2ë‹¨ê³„: Lookup (collect í•„ìš”) ====================

    def build_lookup(self, udi_lf: pl.LazyFrame):
        """
        Lookup í…Œì´ë¸” ìƒì„± (Primaryë§Œ, SecondaryëŠ” ë³„ë„ ì²˜ë¦¬)
        """
        print("ğŸ”§ Lookup í…Œì´ë¸” ìƒì„±...")
        
        # ========== Lookup 1: Primary UDI-DIë§Œ ==========
        self.udi_di_lookup = udi_lf.select([
            'udi_di',
            'manufacturer',
            'brand',
            'model_number',
            'catalog_number',
            'publish_date'
        ]).unique(subset=['udi_di']).collect()
        
        print(f"   UDI-DI Lookup: {len(self.udi_di_lookup):,} ê±´")
        
        # ========== Lookup 2: Full key ==========
        self.mfr_lookup_full = udi_lf.group_by([
            'manufacturer', 'brand', 'catalog_number'
        ]).agg([
            pl.col('udi_di').len().alias('n_versions_full'),
            pl.col('udi_di').alias('udi_list_full'),
            pl.col('model_number').alias('model_list_full'),
            pl.col('publish_date').alias('date_list_full')
        ]).collect()
        
        print(f"   ì œì¡°ì‚¬ Full Lookup: {len(self.mfr_lookup_full):,} ê±´")
        
        # ========== Lookup 3: Partial key ==========
        self.mfr_lookup_partial = udi_lf.group_by([
            'manufacturer', 'brand'
        ]).agg([
            pl.col('udi_di').len().alias('n_versions_partial'),
            pl.col('udi_di').alias('udi_list_partial'),
            pl.col('catalog_number').alias('catalog_list_partial'),
            pl.col('model_number').alias('model_list_partial'),
            pl.col('publish_date').alias('date_list_partial')
        ]).collect()
        
        print(f"   ì œì¡°ì‚¬ Partial Lookup: {len(self.mfr_lookup_partial):,} ê±´")
        
    # ==================== 3-5ë‹¨ê³„: ë§¤ì¹­/í•´ê²° (chunk ì²˜ë¦¬) ====================
    
    def process_all(
        self,
        maude_lf: pl.LazyFrame,
        output_path: Path,
        chunk_size: int = 1_000_000
    ):
        """
        ì „ì²´ íŒŒì´í”„ë¼ì¸ (UDI ë§¤í•‘ í…Œì´ë¸” í™œìš©)
        """
        print("\nğŸ”§ ë§¤ì¹­ ë‹¨ê³„ (UDI ë§¤í•‘ + ì œì¡°ì‚¬ ë§¤ì¹­)...")
        
        def transform_chunk(chunk_lf: pl.LazyFrame) -> pl.LazyFrame:
            # ========== Step 1: UDI ë§¤í•‘ í…Œì´ë¸” join (ì‘ê³  ë¹ ë¦„!) ==========
            matched = chunk_lf.join(
                self.udi_mapping.lazy(),
                on='udi_combined',
                how='left'
            )
            
            # ========== Step 2: Full key ë§¤ì¹­ ==========
            matched = matched.join(
                self.mfr_lookup_full.lazy(),
                left_on=['mfr_std', 'brand', 'catalog_number'],
                right_on=['manufacturer', 'brand', 'catalog_number'],
                how='left',
                suffix='_full'
            )
            
            # ========== Step 3: Partial key ë§¤ì¹­ ==========
            matched = matched.join(
                self.mfr_lookup_partial.lazy(),
                left_on=['mfr_std', 'brand'],
                right_on=['manufacturer', 'brand'],
                how='left',
                suffix='_partial'
            )
            
            # ========== Step 4: ë‹¨ì¼ ë§¤ì¹­ë§Œ ì„±ê³µ ==========
            matched = matched.with_columns([
                pl.when(pl.col('n_versions_full') == 1)
                .then(pl.col('udi_list_full').list.first())
                .otherwise(None)
                .alias('matched_udi_full'),
                
                pl.when(pl.col('n_versions_full') == 1)
                .then(pl.col('model_list_full').list.first())
                .otherwise(None)
                .alias('matched_model_full'),
                
                pl.when(pl.col('n_versions_partial') == 1)
                .then(pl.col('udi_list_partial').list.first())
                .otherwise(None)
                .alias('matched_udi_partial'),
                
                pl.when(pl.col('n_versions_partial') == 1)
                .then(pl.col('catalog_list_partial').list.first())
                .otherwise(None)
                .alias('matched_catalog_partial'),
                
                pl.when(pl.col('n_versions_partial') == 1)
                .then(pl.col('model_list_partial').list.first())
                .otherwise(None)
                .alias('matched_model_partial'),
            ])
            
            # ========== Step 5: ìš°ì„ ìˆœìœ„ í†µí•© ==========
            matched = matched.with_columns([
                # device_version_id: UDI ë§¤í•‘ ìš°ì„ 
                pl.coalesce([
                    'mapped_primary_udi',      # UDI ë§¤í•‘ (direct/secondary)
                    'matched_udi_full',        # ì œì¡°ì‚¬ Full (ë‹¨ì¼)
                    'matched_udi_partial',     # ì œì¡°ì‚¬ Partial (ë‹¨ì¼)
                    'udi_combined',            # Fallback
                ]).alias('device_version_id'),
                
                # manufacturer: UDI ë§¤í•‘ ìš°ì„ 
                pl.coalesce([
                    'mapped_manufacturer',
                    'manufacturer',
                ]).alias('manufacturer_final'),
                
                # brand
                pl.coalesce([
                    'mapped_brand',
                    'brand',
                ]).alias('brand_final'),
                
                # model_number
                pl.coalesce([
                    'mapped_model_number',
                    'matched_model_full',
                    'matched_model_partial',
                ]).alias('model_number_final'),
                
                # catalog_number
                pl.coalesce([
                    'mapped_catalog_number',
                    'catalog_number',
                    'matched_catalog_partial',
                ]).alias('catalog_number_final'),
                
                # match_source
                pl.when(pl.col('udi_match_type') == 'udi_direct')
                .then(pl.lit('udi_direct'))
                .when(pl.col('udi_match_type') == 'udi_secondary')
                .then(pl.lit('udi_secondary'))
                .when(pl.col('matched_udi_full').is_not_null())
                .then(pl.lit('mfr_full_single'))
                .when(pl.col('matched_udi_partial').is_not_null())
                .then(pl.lit('mfr_partial_single'))
                .when(pl.col('n_versions_full') > 1)
                .then(pl.lit('mfr_full_multiple'))
                .when(pl.col('n_versions_partial') > 1)
                .then(pl.lit('mfr_partial_multiple'))
                .when(pl.col('udi_match_type') == 'udi_no_match')
                .then(pl.lit('udi_no_match'))
                .otherwise(pl.lit('no_match'))
                .alias('match_source')
            ])
            
            # ì»¬ëŸ¼ ì„ íƒ
            original_cols = chunk_lf.collect_schema().names()
            final_cols = [
                *original_cols,
                'device_version_id',
                'manufacturer_final',
                'brand_final',
                'model_number_final',
                'catalog_number_final',
                'match_source',
            ]
            
            return matched.select([c for c in final_cols if c in matched.collect_schema().names()])
        
        process_lazyframe_in_chunks(
            lf=maude_lf,
            transform_func=transform_chunk,
            output_path=output_path,
            chunk_size=chunk_size,
            desc="UDI ë§¤í•‘ + ì œì¡°ì‚¬ ë§¤ì¹­"
        )
    
    def _post_process_complex_cases(self, input_path: Path, chunk_size: int):
        """í›„ì²˜ë¦¬ - ë‹¤ì¤‘ ë§¤ì¹­ê³¼ Tier 3 ì²˜ë¦¬"""
        print("\nğŸ”§ í›„ì²˜ë¦¬ (ë‹¤ì¤‘ ë§¤ì¹­ & Tier 3)...")
        
        lf = pl.scan_parquet(input_path)
        
        # ì œì¡°ì‚¬ë³„ ì¤€ìˆ˜ìœ¨
        compliance = lf.group_by('mfr_std').agg([
            (pl.col('udi_combined').is_null().sum() / pl.len()).alias('missing_rate')
        ]).collect()
        
        low_compliance_mfrs = compliance.filter(
            pl.col('missing_rate') > self.config.LOW_COMPLIANCE_THRESHOLD
        )['mfr_std'].to_list()
        
        def resolve_chunk(chunk_lf: pl.LazyFrame) -> pl.LazyFrame:
            # ë‹¤ì¤‘ ë§¤ì¹­ + no_match â†’ Tier 3 ì²˜ë¦¬
            chunk_lf = chunk_lf.with_columns([
                pl.when(
                    pl.col('match_source').is_in([
                        'mfr_full_multiple',
                        'mfr_partial_multiple',
                        'no_match'
                    ])
                )
                .then(
                    # UDI ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš© (ì •ë³´ ì—†ì–´ë„ UDIëŠ” ì‚´ë¦¼)
                    pl.when(pl.col('udi_combined').is_not_null())
                      .then(pl.col('udi_combined'))
                      # UDI ì—†ìœ¼ë©´ Tier 3 ID ìƒì„±
                      .when(pl.col('mfr_std').is_in(low_compliance_mfrs))
                      .then(pl.concat_str([
                          pl.lit('LOW_'), pl.col('mfr_std'), pl.lit('_'), pl.col('brand_final')
                      ]))
                      .otherwise(pl.concat_str([
                          pl.lit('UNK_'), pl.col('mfr_std'), pl.lit('_'), 
                          pl.col('brand_final'), pl.lit('_'), pl.col('catalog_number_final')
                      ]))
                )
                .otherwise(pl.col('device_version_id'))
                .alias('device_version_id'),
                
                # ì‹ ë¢°ë„
                pl.when(pl.col('match_source') == 'udi_direct')
                  .then(pl.lit('HIGH'))
                  .when(pl.col('match_source').str.contains('single'))
                  .then(pl.lit('MEDIUM'))
                  .when(pl.col('match_source').str.contains('multiple'))
                  .then(pl.lit('LOW'))  # ë‹¤ì¤‘ ë§¤ì¹­ ì‹¤íŒ¨
                  .when(pl.col('udi_combined').is_not_null())
                  .then(pl.lit('MEDIUM'))  # UDI ìˆì§€ë§Œ ì •ë³´ ì—†ìŒ
                  .otherwise(pl.lit('VERY_LOW'))
                  .alias('udi_confidence'),
                
                pl.col('match_source').alias('final_source')
            ])
            
            return chunk_lf
        
        output_path = input_path.parent / f"{input_path.stem}_resolved.parquet"
        
        process_lazyframe_in_chunks(
            lf=lf,
            transform_func=resolve_chunk,
            output_path=output_path,
            chunk_size=chunk_size,
            desc="ë‹¤ì¤‘ ë§¤ì¹­ & Tier 3 ì²˜ë¦¬"
        )
        
        print(f"âœ… ìµœì¢… ê²°ê³¼: {output_path}")
        return output_path
    
    # ==================== ì „ì²´ ì‹¤í–‰ ====================

    def process(
        self,
        maude_lf: pl.LazyFrame,
        udi_lf: pl.LazyFrame,
        output_path: Path,
        chunk_size: int = 50_000
    ) -> Path:
        """ì „ì²´ íŒŒì´í”„ë¼ì¸"""
        print("="*60)
        print("UDI ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì‹œì‘ (íš¨ìœ¨ì  ë§¤í•‘)")
        print("="*60)
        
        # 1. ì „ì²˜ë¦¬
        maude_lf = self.preprocess_maude(maude_lf)
        udi_lf = self.preprocess_udi_db(udi_lf)
        
        # 2. ì œì¡°ì‚¬ëª… ì •ê·œí™”
        self.normalize_manufacturers(maude_lf, udi_lf)
        maude_lf = self.apply_normalization(maude_lf)
        
        # 3. Lookup ìƒì„± (Primary + ì œì¡°ì‚¬)
        self.build_lookup(udi_lf)
        
        # 4. UDI ë§¤í•‘ í…Œì´ë¸” ìƒì„± (Primary + Secondary) â† ì‹ ê·œ!
        self.build_udi_mapping(maude_lf, udi_lf, chunk_size)
        
        # 5-6. ë§¤ì¹­/í•´ê²° (chunk)
        temp_path = output_path.parent / f"{output_path.stem}_temp.parquet"
        self.process_all(maude_lf, temp_path, chunk_size)
        
        # 7. í›„ì²˜ë¦¬
        final_path = self._post_process_complex_cases(temp_path, chunk_size)
        
        # 8. ìµœì¢… íŒŒì¼ ì´ë™
        final_path.rename(output_path)
        temp_path.unlink(missing_ok=True)
        
        # í†µê³„
        print("\n" + "="*60)
        print("ğŸ“Š ìµœì¢… ê²°ê³¼")
        print("="*60)
        
        result_lf = pl.scan_parquet(output_path)
        total = result_lf.select(pl.len()).collect().item()
        
        match_stats = result_lf.group_by('match_source').agg([
            pl.len().alias('count'),
            (pl.len() / total * 100).round(2).alias('percent')
        ]).collect().sort('count', descending=True)
        
        print("\në§¤ì¹­ ì¶œì²˜ ë¶„í¬:")
        print(match_stats)
        
        print(f"\nâœ… ì´ {total:,} ê±´ ì²˜ë¦¬ ì™„ë£Œ!")
        print(f"ğŸ“ ê²°ê³¼: {output_path}")
        
        return output_path

    def build_udi_mapping(self, maude_lf: pl.LazyFrame, udi_lf: pl.LazyFrame, chunk_size: int = 50_000):
        """
        UDI ë§¤í•‘ í…Œì´ë¸” ìƒì„± (SecondaryëŠ” chunk ì²˜ë¦¬)
        """
        print("ğŸ”§ UDI ë§¤í•‘ í…Œì´ë¸” ìƒì„±...")
        
        # ========== Step 1: Unique UDI ì¶”ì¶œ ==========
        unique_udi = maude_lf.select([
            'udi_combined'
        ]).unique().filter(
            pl.col('udi_combined').is_not_null()
        ).collect()
        
        print(f"   Unique UDI: {len(unique_udi):,} ê±´")
        
        # ========== Step 2: Primary ë§¤ì¹­ ==========
        udi_with_primary = unique_udi.lazy().join(
            self.udi_di_lookup.lazy(),
            left_on='udi_combined',
            right_on='udi_di',
            how='left',
        ).with_columns([
            pl.col('manufacturer').is_not_null().alias('primary_matched')
        ])
        
        # Primary ì„±ê³µ/ì‹¤íŒ¨ ë¶„ë¦¬ (collect - ì‘ìŒ)
        primary_success = udi_with_primary.filter(pl.col('primary_matched')).collect()
        primary_failed = udi_with_primary.filter(~pl.col('primary_matched')).collect()
        
        print(f"   - Primary ë§¤ì¹­ ì„±ê³µ: {len(primary_success):,} ê±´")
        print(f"   - Primary ë§¤ì¹­ ì‹¤íŒ¨: {len(primary_failed):,} ê±´")
        
        # ========== Step 3: Secondary ë§¤ì¹­ (chunk ì²˜ë¦¬!) ==========
        schema = udi_lf.collect_schema()
        secondary_cols = [c for c in schema.names() if c.startswith('identifiers_') and c.endswith('_id')]
        
        if secondary_cols and len(primary_failed) > 0:
            print(f"   Secondary ë§¤ì¹­ ì‹œë„ ì¤‘... ({len(secondary_cols)}ê°œ ì»¬ëŸ¼)")
            
            # Primary ì‹¤íŒ¨í•œ UDI ë¦¬ìŠ¤íŠ¸
            failed_udi_list = primary_failed['udi_combined'].to_list()
            failed_udi_set = set(failed_udi_list)  # ë¹ ë¥¸ lookupìš©
            
            print(f"   ë§¤ì¹­ ëŒ€ìƒ UDI: {len(failed_udi_set):,} ê±´")
            
            # ========== UDI DBë¥¼ chunkë¡œ ì²˜ë¦¬ ==========
            def build_secondary_mapping_chunk(chunk_lf: pl.LazyFrame) -> pl.LazyFrame:
                """ê° chunkì—ì„œ secondary ë§¤ì¹­ ì°¾ê¸°"""
                # concat_listë¡œ secondary ì»¬ëŸ¼ í•©ì¹˜ê¸°
                chunk_with_list = chunk_lf.with_columns([
                    pl.concat_list(secondary_cols).alias('secondary_list')
                ]).select([
                    'udi_di',
                    'manufacturer',
                    'brand',
                    'model_number',
                    'catalog_number',
                    'secondary_list'
                ])
                
                # explode (chunk ë‹¨ìœ„ë¼ ì•ˆì „)
                exploded = chunk_with_list.explode('secondary_list').filter(
                    pl.col('secondary_list').is_not_null()
                )
                
                # Primary ì‹¤íŒ¨í•œ UDIì™€ ë§¤ì¹­ë˜ëŠ” ê²ƒë§Œ í•„í„°
                matched = exploded.filter(
                    pl.col('secondary_list').is_in(failed_udi_list)
                )
                
                # group_by
                return matched.group_by('secondary_list').agg([
                    pl.col('udi_di').n_unique().alias('n_primary'),
                    pl.col('udi_di').first().alias('primary_udi'),
                    pl.col('manufacturer').first().alias('manufacturer'),
                    pl.col('brand').first().alias('brand'),
                    pl.col('model_number').first().alias('model_number'),
                    pl.col('catalog_number').first().alias('catalog_number'),
                ])
            
            # chunk ì²˜ë¦¬
            temp_secondary_path = Path("data/temp_secondary_mapping.parquet")
            
            process_lazyframe_in_chunks(
                lf=udi_lf,
                transform_func=build_secondary_mapping_chunk,
                output_path=temp_secondary_path,
                chunk_size=chunk_size,  # UDI DB chunk í¬ê¸°
                desc="Secondary ë§¤í•‘ ìƒì„±"
            )
            
            # ê²°ê³¼ ë¡œë“œ & í†µí•© (ì¤‘ë³µ ì œê±°)
            secondary_mapping_all = pl.scan_parquet(temp_secondary_path).group_by(
                'secondary_list'
            ).agg([
                pl.col('n_primary').sum().alias('n_primary'),  # chunk ê°„ í•©ì‚°
                pl.col('primary_udi').first().alias('primary_udi'),
                pl.col('manufacturer').first().alias('manufacturer'),
                pl.col('brand').first().alias('brand'),
                pl.col('model_number').first().alias('model_number'),
                pl.col('catalog_number').first().alias('catalog_number'),
            ]).collect()
            
            print(f"   - Secondary ë§¤í•‘ ìƒì„± ì™„ë£Œ: {len(secondary_mapping_all):,} ê±´")
            
            # Primary ì‹¤íŒ¨í•œ UDIì™€ join
            secondary_matched = primary_failed.lazy().join(
                secondary_mapping_all.lazy(),
                left_on='udi_combined',
                right_on='secondary_list',
                how='left'
            ).with_columns([
                (pl.col('n_primary') == 1).alias('secondary_matched')
            ]).collect()
            
            # ì„ì‹œ íŒŒì¼ ì‚­ì œ
            temp_secondary_path.unlink(missing_ok=True)
            
            secondary_success_count = secondary_matched.filter(
                pl.col('secondary_matched')
            ).shape[0]
            
            print(f"   - Secondary ë§¤ì¹­ ì„±ê³µ: {secondary_success_count:,} ê±´ (ë‹¨ì¼ Primary)")
            print(f"   - Secondary ë§¤ì¹­ ì‹¤íŒ¨: {len(primary_failed) - secondary_success_count:,} ê±´")
            
        else:
            print("   âš ï¸  Secondary ë§¤ì¹­ Skip")
            secondary_matched = primary_failed.with_columns([
                pl.lit(False).alias('secondary_matched'),
                pl.lit(None).cast(pl.Utf8).alias('primary_udi'),
                pl.lit(None).cast(pl.Utf8).alias('manufacturer'),
                pl.lit(None).cast(pl.Utf8).alias('brand'),
                pl.lit(None).cast(pl.Utf8).alias('model_number'),
                pl.lit(None).cast(pl.Utf8).alias('catalog_number'),
            ])
        
        # ========== Step 4: ë§¤í•‘ í…Œì´ë¸” í†µí•© ==========
        # Primary ì„±ê³µ
        primary_mapping = primary_success.select([
            'udi_combined',
            pl.col('udi_combined').alias('mapped_primary_udi'),
            pl.col('manufacturer').alias('mapped_manufacturer'),
            pl.col('brand').alias('mapped_brand'),
            pl.col('model_number').alias('mapped_model_number'),
            pl.col('catalog_number').alias('mapped_catalog_number'),
            pl.lit('udi_direct').alias('udi_match_type')
        ])
        
        # Secondary ì„±ê³µ
        secondary_success_mapping = secondary_matched.filter(
            pl.col('secondary_matched')
        ).select([
            'udi_combined',
            pl.col('primary_udi').alias('mapped_primary_udi'),
            pl.col('manufacturer').alias('mapped_manufacturer'),
            pl.col('brand').alias('mapped_brand'),
            pl.col('model_number').alias('mapped_model_number'),
            pl.col('catalog_number').alias('mapped_catalog_number'),
            pl.lit('udi_secondary').alias('udi_match_type')
        ])
        
        # Secondary ì‹¤íŒ¨
        secondary_failed_mapping = secondary_matched.filter(
            ~pl.col('secondary_matched')
        ).select([
            'udi_combined',
            pl.col('udi_combined').alias('mapped_primary_udi'),
            pl.lit(None).cast(pl.Utf8).alias('mapped_manufacturer'),
            pl.lit(None).cast(pl.Utf8).alias('mapped_brand'),
            pl.lit(None).cast(pl.Utf8).alias('mapped_model_number'),
            pl.lit(None).cast(pl.Utf8).alias('mapped_catalog_number'),
            pl.lit('udi_no_match').alias('udi_match_type')
        ])
        
        # í†µí•©
        self.udi_mapping = pl.concat([
            primary_mapping,
            secondary_success_mapping,
            secondary_failed_mapping
        ])
        
        print(f"   âœ… ìµœì¢… UDI ë§¤í•‘: {len(self.udi_mapping):,} ê±´")
        print(f"      - udi_direct: {(self.udi_mapping['udi_match_type']=='udi_direct').sum():,}")
        print(f"      - udi_secondary: {(self.udi_mapping['udi_match_type']=='udi_secondary').sum():,}")
        print(f"      - udi_no_match: {(self.udi_mapping['udi_match_type']=='udi_no_match').sum():,}")